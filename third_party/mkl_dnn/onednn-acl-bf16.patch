diff --git a/src/cpu/aarch64/acl_inner_product_utils.cpp b/src/cpu/aarch64/acl_inner_product_utils.cpp
index 8a8d1cc93..f2849d4c6 100644
--- a/src/cpu/aarch64/acl_inner_product_utils.cpp
+++ b/src/cpu/aarch64/acl_inner_product_utils.cpp
@@ -134,6 +134,11 @@ status_t init_conf_ip(acl_ip_conf_t &aip, memory_desc_t &src_md,
     const auto &post_ops = attr.post_ops_;
     aip.with_sum = (post_ops.len() == 1) && post_ops.entry_[0].is_sum();
 
+    // Fast math mode
+    auto math_mode = get_fpmath_mode();
+    bool is_fastmath_enabled = one_of(math_mode, fpmath_mode::bf16, fpmath_mode::any);
+    aip.fc_info.enable_fast_math = is_fastmath_enabled;
+
     // clang-format off
     // Validate convolution manually to check for return status
     auto acl_st = arm_compute::NEFullyConnectedLayer::validate(
diff --git a/src/cpu/aarch64/matmul/acl_matmul_utils.cpp b/src/cpu/aarch64/matmul/acl_matmul_utils.cpp
index bf35ef83c..620850410 100644
--- a/src/cpu/aarch64/matmul/acl_matmul_utils.cpp
+++ b/src/cpu/aarch64/matmul/acl_matmul_utils.cpp
@@ -82,6 +82,11 @@ status_t init_conf_matmul(acl_matmul_conf_t &amp, memory_desc_t &src_md,
             = arm_compute::TensorInfo(arm_compute::TensorShape(N, M, 1, batch),
                     1, arm_compute::DataType::F32);
 
+    // Fast-math mode
+    auto math_mode = get_fpmath_mode();
+    bool is_fastmath_enabled = one_of(math_mode, fpmath_mode::bf16, fpmath_mode::any);
+    amp.gemm_info.set_fast_math(is_fastmath_enabled);
+
     // Fused ReLU activation
     amp.gemm_info.set_activation_info(get_acl_act(attr));
     // Set alpha (output scaling)
